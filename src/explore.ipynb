{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore here\n",
    "\n",
    "It's recommended to use this notebook for exploration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install dependencies\n",
    "\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML content downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Download the full HTML from the url\n",
    "\n",
    "resource_url = \"https://ycharts.com/companies/TSLA/revenues\"\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "response = requests.get(resource_url, headers=headers)\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    with open(\"revenues.html\", \"wb\") as dataset:\n",
    "    #OJO: así no funcionaba faltaba la terminación .html!!!  with open(\"revenues\", \"wb\") as dataset:\n",
    "      dataset.write(response.content) # response.text is a string and will not work\n",
    "      #OJO: con la terminación .text no funcionaba!!! dataset.write(response.text)\n",
    "    print(\"HTML content downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"Request failed with status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. A) Transform the HTML (Just fetching last 4 years revenue data)\n",
    "\n",
    "with open(\"revenues.html\", \"r\", encoding =\"utf-8\") as file: # 'utf-8' is common but may need adjustment\n",
    "  html_content = file.read()\n",
    "\n",
    "# Turning the downloaded content into html identifying it as a BeautifulSoup object (transforming the scrapped content of previous steff into clean html)\n",
    "\n",
    "soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarterly revenue table found!\n"
     ]
    }
   ],
   "source": [
    "#Step 3) Find the table with the quarterly evolution and store the data in a DataFrame.\n",
    "\n",
    "#Identify and target in the url the specific html content we are interested in (Tesla revenue table): \n",
    "#<div class=\"panel panel-data\"><div class=\"panel-header\"><h3 class=\"panel-title\">Revenue (Quarterly) Chart</h3>\n",
    "\n",
    "soup_html = soup.find(\"div\", class_=\"panel panel-data\").find(\"div\", class_=\"panel-header\").find(\"h3\", class_=\"panel-title\")\n",
    "\n",
    "#Confirm if the element (revenue table) has been found\n",
    "if soup_html:\n",
    "  print(\"Quarterly revenue table found!\")\n",
    "else: print(\"Quarterly revenue table not found :'(. Check html search criteria\")\n",
    "\n",
    "# IMPORTANT: The `<h3>` element itself does not contain the data requested, it just points to where it is \n",
    "# Using `find_next('table')` to locate a nearby `<table>` element that likely holds the actual revenue data.\n",
    "\n",
    "revenues = soup_html.find_next(\"table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no NaN found\n",
      "                 Dates  Values\n",
      "0   September 30, 2024  25.18B\n",
      "1        June 30, 2024  25.50B\n",
      "2       March 31, 2024  21.30B\n",
      "3    December 31, 2023  25.17B\n",
      "4   September 30, 2023  23.35B\n",
      "5        June 30, 2023  24.93B\n",
      "6       March 31, 2023  23.33B\n",
      "7    December 31, 2022  24.32B\n",
      "8   September 30, 2022  21.45B\n",
      "9        June 30, 2022  16.93B\n",
      "10      March 31, 2022  18.76B\n",
      "11   December 31, 2021  17.72B\n",
      "12  September 30, 2021  13.76B\n",
      "13       June 30, 2021  11.96B\n",
      "14      March 31, 2021  10.39B\n",
      "15   December 31, 2020  10.74B\n",
      "16  September 30, 2020  8.771B\n",
      "17       June 30, 2020  6.036B\n",
      "18      March 31, 2020  5.985B\n",
      "19   December 31, 2019  7.384B\n",
      "20  September 30, 2019  6.303B\n",
      "21       June 30, 2019   6.35B\n",
      "22      March 31, 2019  4.541B\n",
      "23   December 31, 2018  7.226B\n",
      "24  September 30, 2018  6.824B\n",
      "Index(['Dates', 'Values'], dtype='object')\n",
      "RangeIndex(start=0, stop=25, step=1)\n",
      "revenues_df is a DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Step 4) Process the DataFrame\n",
    "\n",
    "#Fetching and cleaning the data (content of the table) in a visual way by turning into a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dates = [] \n",
    "values = [] \n",
    "\n",
    "for row in revenues.find_all(\"tr\"): \n",
    "  cells = row.find_all('td') \n",
    "  if len(cells) >= 2: #Check if the rows has at least 2 cells (for Dates and Values)\n",
    "    #using text.strip() to get clean data without $, comas, or other signs\n",
    "    dates.append(cells[0].text.strip())  # Since the \"Value\" column initially printed \"...\" instead of amounts, making sure I extract and clean the date using text.strip()\n",
    "    \n",
    "    # Find the specific element containing the value \n",
    "    value_element = row.find(\"td\", class_=\"text-right\") #taken from one revenue value html by inspecting element\n",
    "\n",
    "    if value_element:\n",
    "      values.append(value_element.text.strip()) # Extract and clean the value element (since it initally appeared as \"...\" instead of values)\n",
    "    else: \n",
    "      values.append(\"N/A\") # Handle cases where the value element is not found\n",
    "\n",
    "# Create a dictionary with the extracted data to make it easier to turn into dataframe\n",
    "data = {\"Dates\": dates, \"Values\": values}\n",
    "\n",
    "# Create the Pandas DataFrame\n",
    "revenues_df = pd.DataFrame(data)\n",
    "\n",
    "# Data cleanse triple check \n",
    "# by removing empty cells or NaN\n",
    "revenues_df.dropna(subset=[\"Dates\", \"Values\"], inplace=True)\n",
    "# Removing rows with empty strings in \"Values\"\n",
    "revenues_df = revenues_df[revenues_df[\"Values\"] != ''] \n",
    "# Remove rows with only whitespace in \"Values\"\n",
    "revenues_df = revenues_df[revenues_df[\"Values\"].str.strip() != '']  \n",
    "\n",
    "# Checking it there are NaN \n",
    "if revenues_df.isna().any().any() == False:\n",
    "  print(\"no NaN found\")\n",
    "else:\n",
    "  print(\"There are NaN\")\n",
    "\n",
    "print(revenues_df)\n",
    "print(revenues_df.columns)\n",
    "print(revenues_df.index)\n",
    "\n",
    "if type(revenues_df) == pd.core.frame.DataFrame:\n",
    "    print(\"revenues_df is a DataFrame\")\n",
    "else:\n",
    "    print(\"revenues_df is not a DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 5: Store the data in sqlite\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Connect to the database or create it if it doesn't exist\n",
    "con = sqlite3.connect(\"revenues.db\") #This data document is already created and stored in this github/workspaces/web-scraping-project-tutorialDianaM/src/revenues.db\n",
    "\n",
    "con.commit()\n",
    "\n",
    "\n",
    "#CREATE: Generate a table named QUARTERLY REVENUES with 2 columns: DATES AND VALUES\n",
    "con.execute(\"\"\"CREATE TABLE IF NOT EXISTS REVENUES(\n",
    "    DATES TEXT NOT NULL PRIMARY KEY,  -- Changed DATES to TEXT\n",
    "    REVENUE TEXT NOT NULL            -- Changed REVENUE to TEXT\n",
    ")\"\"\")\n",
    "\n",
    "# Include the clean data in it, as we saw in the database module.\n",
    "\n",
    "# This query defines the operation of inserting data into the specified columns (DATES, REVENUE) of the table (QUARTERLY_REVENUES). \n",
    "# The placeholders (?) will be filled with values from the DataFrame. \n",
    "\n",
    "insert_query = \"INSERT OR IGNORE INTO REVENUES (DATES, REVENUE) VALUES (?, ?)\" \n",
    "\n",
    "# Iterate Through DataFrame Rows and Execute INSERT\n",
    "\n",
    "for index, row in revenues_df.iterrows():\n",
    "    con.execute(insert_query, (row[\"Dates\"], row[\"Values\"]))\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Visualize the data. What types of visualizations can we make? \n",
    "# Suggest at least 3 and plot them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
